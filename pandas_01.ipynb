{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メモ)Python使ったことない人向け\n",
    "- print(\"文字列\") でデバッグ用の標準出力ができます。\"\\n\"で改行できます。\n",
    "- インデントは半角スペース4つがお作法。\n",
    "    - 行の先頭に余計な空白などがあるとダメです。\n",
    "    - タブキーに半角スペース4つを割り当てても良い。\n",
    "- import文を使って各種ライブラリを参照します。\n",
    "    - anacondaインストールならpandasはimport文で呼ぶだけです。\n",
    "    - pandasはpdと略すのが世の慣習です。(NumPyはnp)\n",
    "- コメントアウト1行は「#」を、複数行は「＂」か「’」を3つ続けて打ちます。\n",
    "- 変数に型宣言はありません。\n",
    "\n",
    "***\n",
    "# メモ)Jupyter Notebook\n",
    "- ツールバーの\"View\">\"Toggle Line Number\"を選択すると、コードの行番号が出ます\n",
    "- \"Cell\">\"Run All\"　で全セルのプログラムが実行されます。(遅れて来られた方など一気に実行したい人はこちらをどうぞ)\n",
    "- アウトプット行が煩わしくなってきたら、\"Cell\">\"All Output\" > \"Clear\"などで消すこともできます。\n",
    "***\n",
    "# 本教材の進め方\n",
    "- コードの各セル(グレーの部分)を選択して、上の実行ボタン(▲と|)をポチポチします\n",
    "    - あえてめんどくさくしているのは、居眠り防止のためです。\n",
    "    - と言いたいところですが、単純にコンテンツが長くなりすぎるためです。\n",
    "\n",
    "***\n",
    "## 補足\n",
    "-　import pandas as pd　やCSV読込は、1つのプログラムの先頭で1回呼ぶだけでOKです。\n",
    "- ただし今回は途中参加の方や、実行中にPCが落ちて再起動した場合など焦ることもあるので、あえてJupyterの1セル単位でimportをしています。\n",
    "\n",
    "***\n",
    "## 懺悔\n",
    "- 資料中のクォーテーション表記や、DataFrameのカラム表記に一貫していない箇所があります。。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 第1章 初めの一歩\n",
    "## 1) ゼロからpandasのデータを作る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1) Series(一元配列型のデータ)を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#値のみのSeries\n",
    "obj = pd.Series([110.8,  1]) \n",
    "print(obj)\n",
    "\n",
    "#左に出てくる0,1がインデックス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2) DataFrame(二元配列型のデータ)を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#DataFrameはdfと略すことが多いです\n",
    "df = pd.DataFrame({ '月' : pd.Timestamp('20190501'), '通貨' : ['USD', 'JPY'],'金額' : [110.8,1] })\n",
    "\n",
    "print(df)\n",
    "# カラムはデフォルトで、アルファベットの昇順で出てきます。任意の順番に並び替えることもできます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) CSVからDataFrameをつくる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file=\"./iris.csv\"\n",
    "df=pd.read_csv(csv_file) #デフォルトのエンコードはutf-8。　encoding=\"SHIFT-JIS\"とすればSHIFT-JISも読める。\n",
    "\n",
    "print(df[:5]) #先頭5レコードだけ出力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3) サンプルを動かす"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1) SQL例文との比較\n",
    "    SELECT \n",
    "      Name, avg(SepalLength),avg(PetalLength)\n",
    "\n",
    "    FROM (iris.csvのデータ)\n",
    "\n",
    "    WHERE \n",
    "      SepalLength >3 and PetalLength < 6\n",
    "\n",
    "    GROUP BY Name\n",
    "\n",
    "    ORDER BY Name ASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#FROM句 csvを読み込む\n",
    "df=pd.read_csv(\"./iris.csv\") #デフォルトのエンコードはutf-8\n",
    "print(\"\\n#FROM句----------\")\n",
    "print(df[:10])#先頭10レコードだけ出力\n",
    "\n",
    "\n",
    "#SELECT句、カラムを絞る および列順の指定 \n",
    "df=df[[\"Name\",\"SepalLength\",\"PetalLength\"]]\n",
    "print(\"\\n#SELECT句--------------------\")\n",
    "print(df[:10])#先頭10レコードだけ出力\n",
    "\n",
    "\n",
    "#WHERE句 条件を絞る\n",
    "df=df[df[\"SepalLength\"]>3]\n",
    "df=df[df[\"PetalLength\"]<6]\n",
    "print(\"\\n#WHERE句--------------------\")\n",
    "print(df[:10])\n",
    "\n",
    "#GROUP BY句 条件で集計する &ORDER BY句 Name順に並び替える\n",
    "df=df.groupby([\"Name\"]).mean().sort_index()\n",
    "print(\"\\n#GROUP BY句&ORDER BY句----------\")\n",
    "print(df)\n",
    "\n",
    "\n",
    "#ついでにCSV出力\n",
    "df.to_csv(\"集計結果.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 補足) .to_csv() の引数\n",
    "\n",
    "- path_or_buf => 出力するファイル名。省略した場合は、コンソール上に文字列として出力されます。\n",
    "- sep => 区切り文字 (デフォルト: , (カンマ) )\n",
    "- index => 行名を出力するかどうか。Falseを指定した場合、行名は出力されません。(デフォルト: True)\n",
    "- encoding => 出力する際の文字コード。’utf-8′, ‘shift_jis’, ‘euc_jp’ などを指定。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 第2章 SQL文法と比較\n",
    "## 1) FROM的なもの\n",
    "\n",
    "- CSV以外に、JSONやSQLの結果なども利用できる。\n",
    "- DataFrameの形にさえ変換できれば自由に加工できる。\n",
    "- JOINなどで複数のデータを参照する場合は、それぞれDataFrameを読み込んでから加工する。  \n",
    "    *　各DataFrameは、JOINの前に、集計や不要カラムの除外などを行い、できる限り小さくすると良い。\n",
    "- サイズの大きなデータは、\"chunk\"という機能を使って、n行単位で小分けにして読み込むと負荷が少ない。\n",
    "    * メモリが少ない環境などで有用。\n",
    "    \n",
    "## 2) LIMIT的なもの\n",
    "- df[:10]       \n",
    "    * limit 10と同じ意味。先頭10行を取得する\n",
    "- df[10:]      \n",
    "    * 先頭10〜最終行を取得する\n",
    "- df[10:30]  \n",
    "    * 先頭10〜30行を取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 注) Pythonのループなど出てくるので、ここは参考に読む程度で良い。\n",
    "'''\n",
    "chunkを用いた例 \n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#5行ずつデータを読み込む\n",
    "df_chunks = pd.read_csv(\"./iris.csv\", chunksize=5, dtype=\"object\")\n",
    "\n",
    "#5行ずつ読み込んだDataFrameから、所定のカラムのみ取得してlist型の変数に格納\n",
    "pieces = [df[[\"Name\",\"SepalLength\",\"PetalLength\"]] for df in df_chunks]\n",
    "\n",
    "#list型変数に格納された複数のDataFrameを結合(Unionのように、縦に重ねる)\n",
    "s =  pd.concat(pieces)\n",
    "\n",
    "print(s[:15]) #先頭15レコード出力(実際は150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "## 3) SELECT的なもの\n",
    "\n",
    "### A. 基本形(1列のみ指定)\n",
    "- df['Name']\n",
    "    * メリット) カラム名の空白OK。複数列OK。日本語カラムOK。\n",
    "    * デメリット) 長い。\n",
    "\n",
    "- df.Name\n",
    "    * メリット) 短く書ける \n",
    "    * デメリット) カラム名の空白NG。複数列NG。日本語カラムNG。\n",
    "\n",
    "### B. 複数列指定\n",
    "- df[['Name', 'SepalLength, 'PetalLength']]   \n",
    "    * 注意点) 複数選択は[[]] で括る\n",
    " \n",
    "※カラム名の代わりに番号も使える(使いどころはないかも)。    \n",
    "例) df[0]   , df[[0 ,2 ,4]]    \n",
    "※distinctは別の文法を使うので後述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#それぞれ列を指定して、1行目だけを表示\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "print(\"\\n # Name列その1\")\n",
    "print(df[\"Name\"][:1])\n",
    "\n",
    "print(\"\\n # Name列その2\")\n",
    "print(df.Name[:1])\n",
    "\n",
    "print(\"\\n # 複数列の表示\")\n",
    "print(df[[\"Name\", \"SepalLength\", \"PetalLength\"]][:1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. 応用形(loc による行・列指定) <-今覚えなくてOK\n",
    "- 行・列をラベル名で同時指定して抽出できる。( index 名,column名の順) \n",
    "※今回は割愛　　　　\n",
    "\n",
    "- 複数行・複数列の抽出の場合は「:」を使う　　\n",
    "　　\n",
    "- 「:」だけの場合は\"列指定の省略(行のみ抽出)\"または、\"行指定の省略(列のみ抽出)\"となる\n",
    "\n",
    "df =df.loc[:,['Name', 'SepalLength','PetalLength']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "print(df[:5])\n",
    "print(\"\\n #index=1-2を表示\")\n",
    "print(df.loc[1:2,[\"Name\", \"SepalLength\",\"PetalLength\"]])\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n #全ての行を表示\")\n",
    "print(df.loc[:,[\"Name\", \"SepalLength\",\"PetalLength\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4) GROUP BY句的なもの\n",
    "### A. 基本) 1つのキーに対して、1列以上の集計を行う\n",
    "- index=’Name’ 、　value = \"SepalLength\",\"PetalLength\"各々の最大値\n",
    "    * df[[\"Name\",  \"SepalLength\",\"PetalLength\"]] .groupby([\"Name\"]).max() \n",
    "\n",
    "### B. 応用) キーを指定せず、全てのレコードに対して集計を行う\n",
    "- 列全てに対して集計を行う(例:最大値)\n",
    "    * df.max()\n",
    "\n",
    "- 特定の列に対して集計を行う(例:最大値)\n",
    "    * df.max().列名\n",
    "    * df.列名.max()\n",
    "\n",
    "### 注目) GROUP BYをすると、集約されたキーがindexになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "print(\"# NameでGroupBYし、MAXを出力\")\n",
    "print(\"\\n必要なカラムをあらかじめ選択した場合\")\n",
    "print(df[[\"Name\",  \"SepalLength\",\"PetalLength\"]] .groupby([\"Name\"]).max() )\n",
    "print(\"\\nName以外全部集計して出す場合\")\n",
    "print(df.groupby([\"Name\"]).max() )\n",
    "\n",
    "print(\"\\n # indexの指定なし--------------------\")\n",
    "print(df.max())\n",
    "\n",
    "print(\"\\n # SepalLengthの最大だけ出力--------------------\")\n",
    "print(df.max().SepalLength)\n",
    "print(df.SepalLength.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. 応用)複数のキーでGROUP BY & 複数の要約統計量\n",
    "df = df.groupby(['key1','key2']).max()\n",
    "\n",
    "### D. 応用)複数の要約統計量\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 応用)複数のキーでGROUP BY\n",
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "#任意にカラム追加\n",
    "df['Group']=\"A\"  #defaultで全行に\"A\"\n",
    "df['Group'][5:9]=\"B\" # index5-9に\"B\"\n",
    "df['Group'][10:14]=\"C\" # index10-14に\"C\"\n",
    "\n",
    "print(\"\\n # max()のみ出力------------\")\n",
    "print(df.groupby(['Group','Name']).max())\n",
    "print(\"\\n #複数の要約統計量を出力------------\")\n",
    "print( df.groupby(['Group','Name']).describe())\n",
    "\n",
    "#ちょっと警告出るけどスルーしてください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "## 5) ORDER BY的なもの\n",
    "\n",
    "- valueでソートする    \n",
    "    * df.sort_values()\n",
    "- indexでソートする\n",
    "    * df.sort_index()　\n",
    " \n",
    "    \n",
    "### A. sort_values(値の順 / 行方向のみ)\n",
    "- 1つのカラムで昇順ソート\n",
    "     * df.sort_values(by='key1') \n",
    "- 複数カラムで降順ソート\n",
    "    * df.sort_values(by=[’key1’,’key2’],ascending=False ) ) \n",
    "\n",
    "### B. sort_index(index順 / 行方向 )\n",
    "- indexの昇順ソート\n",
    "     * df.sort_index(axis=0,ascending=True) \n",
    "- indexの降順ソート\n",
    "    * df.sort_index(axis=0,ascending=False) \n",
    "\n",
    "※axis=1でカラムの順序の並び替えになる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "print(\"\\n #'PetalLength','PetalWidth'の降順TOP5\")\n",
    "df=df.sort_values(by=['PetalLength','PetalWidth'],ascending=False ) \n",
    "print(df[:5])\n",
    "\n",
    "\n",
    "print(\"\\n # GroupByの平均を出力------------\")\n",
    "df=df.groupby(['Name']).mean()\n",
    "print(df)\n",
    "print(\"\\n # GroupByの平均を出力=> indexの降順------------\")\n",
    "print(df.sort_index(axis=0,ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "## 6) WHERE的なもの(文字列編)  \n",
    "### 6-1) 完全一致\n",
    "#### A. イコール \n",
    "df[ df.列名=='hoge' ]\n",
    "\n",
    "#### B. Not イコール\n",
    "df[ df.列名!='hoge' ]  または  df[~(df.列名=='hoge' )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "print(\"\\n #Nameが'Iris-virginica'\")\n",
    "print(df[df.Name=='Iris-virginica' ][:5])\n",
    "\n",
    "print(\"\\n #Nameが'Iris-virginica'以外\")\n",
    "print(df[~(df.Name=='Iris-virginica' )][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2) 複数条件\n",
    "#### A. in \n",
    "df[ df.列名.isin(['hoge', 'piyo']) ]  \n",
    "#### B. Not in\n",
    "df[~(df.列名.isin(['hoge', 'piyo']) )]\n",
    "\n",
    "\n",
    "※ “~”が否定を示す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "print(\"\\n #Nameが'Iris-virginica'または'Iris-versicolor' \")\n",
    "print(df[df.Name.isin(['Iris-virginica','Iris-versicolor']) ][:5])\n",
    "\n",
    "print(\"\\n #Nameが'Iris-virginica'または'Iris-versicolor' \")\n",
    "print(df[~(df.Name.isin(['Iris-virginica','Iris-versicolor']) )][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3) 部分一致(〜を含む)\n",
    "#### A. like \n",
    "df[df.列名.str.contains('hoge')]\n",
    "\n",
    "\n",
    "#### B. Not like\n",
    "df[~(df.列名.str.contains('hoge'))]\n",
    "\n",
    "### 6-4) 部分一致の複数条件(\"|\"を間に挟む)\n",
    "df[df.列名.str.contains('hoge|piyo')]  \n",
    "    \n",
    "※str.contains()はPythonの文法。正規表現も扱える。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "print(\"\\n #Nameにvirを含む \")\n",
    "print(df[df.Name.str.contains('vir') ])\n",
    "\n",
    "print(\"\\n #Nameにvirを含まない \")\n",
    "print(df[~(df.Name.str.contains('vir') )])\n",
    "\n",
    "\n",
    "print(\"\\n #Nameにset|またはcolorを含む \")\n",
    "print(df[df.Name.str.contains('set|color') ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-5) 複合条件\n",
    "#### 条件A and B\n",
    "df[(df.column_a.str.contains('hoge')) & ~(df.column_b=='piyo' )]    \n",
    " => column_aに'hoge'を含み、かつ、column_bに'piyo'を含まない。\n",
    " \n",
    "#### 条件 A or B\n",
    "df[(df.column_a.str.contains('hoge')) | ~(df.column_b=='piyo' )]    \n",
    " => column_aに'hoge'を含む、または、type_bに'piyo'を含まない。\n",
    "\n",
    "※それぞれの条件は”()”で括る必要がある。   \n",
    "※”&”と”|”は、1つが正解。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "#条件A and B\n",
    "print(\"\\n # Nameに'ver'を含み、かつ、SepalLength>6.5。\")\n",
    "df_1=df[(df.Name.str.contains('ver')) & (df.SepalLength>6.5) ] \n",
    "print(df_1)\n",
    "\n",
    "#条件 A or B\n",
    "print(\"\\n # Nameに’ver'を含まない、または、SepalLength>6.5。\")\n",
    "df_2=df[~(df.Name.str.contains('ver')) | (df.SepalLength>6.5)] \n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "## 7) WHERE的なもの(数字編)  \n",
    "\n",
    "### 7-1)イコール\n",
    "df[df.列名==1000]\n",
    "\n",
    "### 7-2)以上\n",
    "df[df.列名>=1000]\n",
    "\n",
    "### 7-3)以下\n",
    "df[df.列名<=1000]\n",
    "\n",
    "#### 他、より大きい、より小さい などが使える。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "print(\"\\n #SepalWidth==4\")\n",
    "print(df[df.SepalWidth==4])\n",
    "\n",
    "print(\"\\n #SepalWidth>4\")\n",
    "print(df[df.SepalWidth>4])\n",
    "\n",
    "print(\"\\n #SepalWidth<=2\")\n",
    "print(df[df.SepalWidth<=2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重要) 抽出カラムに数字以外のデータ(NaN)があると、意図しない挙動になることがある\n",
    "#### 数字列にNullが含まれると、、\n",
    "カラムは数値型のままで、Nullが\"NaN\"で表示される。   \n",
    "それによって、集計がおかしくなったり、後々の処理でエラーになったりするなどバグの温床になりやすい。  \n",
    "=> 苦しむ前に変換しましょう。(そんなに苦労はない)\n",
    "\n",
    "#### 数字列に文字列が含まれると、、\n",
    "カラム自体がobject型になる    \n",
    "=> これは変換も厄介なので割愛。そもそもの取り込みデータを見直した方が良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nullを含むCSVを使った場合\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"./iris_nan_error.csv\" ,sep=',')\n",
    "print(df[:3])\n",
    "\n",
    "print(\"\\n # NaN含んだ状態で平均値を出力-------\")\n",
    "print(df.groupby(['Name']).mean())\n",
    "\n",
    "print(\"\\n # NaNを0埋めして、平均値を出力-------\")\n",
    "df=df.fillna(0)\n",
    "print(df.groupby(['Name']).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## そもそもNaNとは何か?\n",
    "\"not a number”である\n",
    "- PythonのNone、欠損値が該当する。\n",
    "- csvやDBのデータなど、Nullが含まれているとNaNになる。\n",
    "\n",
    "### 対処法\n",
    "1. NumPy.nan を判定に使って、該当データをあらかじめreplaceする。\n",
    "    - 例) df=df.replace(np.nan, 0)\n",
    "2. df.fillna(0)で、欠損値を穴埋めする\n",
    "3. df.dropna() で、NaNを含む行を削除する。\n",
    "    - SQLのwhere 列名 is not null と同義\n",
    "\n",
    "※必ずしも0に置き換えて良いとは限らない。データを確認し、検討の上で変換すること。\n",
    "\n",
    "### 応用\n",
    "特定のカラムを指定したreplaceなども可能。    \n",
    "文字列のカラムの欠損には\"-\"を入れるなど使い分けができる。  \n",
    "df[['SepalLength ', 'SepalWidth']].replace( np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"./iris_nan_error.csv\" ,sep=',')\n",
    "\n",
    "print(\"\\n # NaNを0に置換-------\")\n",
    "print(df.replace(np.nan, 0)[:3]) \n",
    "\n",
    "print(\"\\n # NaNを0で埋める-------\")\n",
    "print(df.fillna(0)[:3])\n",
    "\n",
    "print(\"\\n # NaNの行を除外-------\")\n",
    "print(df.dropna()[:3]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実はdf.query()というものも存在する\n",
    "わかりやすいが速度が遅いとかなんとか。。    \n",
    "興味があれば検索してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# JOINの説明の前に、ちょっと小ワザ集\n",
    "## 小ワザ1) 要素の追加 \n",
    "存在しない列に対して代入をすると、列が追加される    \n",
    "`df[‘abc] = df.列名a + \"_\" + df.列名b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "df[\"new_column\"]=df.Name + \"_hoge\" \n",
    "print(df[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 小ワザ2) 型の変換  (astype)\n",
    "数値型を文字列型に変換    \n",
    "df[列名].astype(‘str’)　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "print(\"\\n # 元のデータ型-------\")\n",
    "print(df.SepalLength.dtype)\n",
    "\n",
    "print(\"\\n # 文字列に変換した後のデータ型-------\")\n",
    "print(df.SepalLength.astype(\"str\").dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 小ワザ3) カラムのリネーム\n",
    "\n",
    "### 1列のみ  \n",
    "df.rename(columns ={\"列A\": \"a\"})\n",
    "\n",
    "### 複数\n",
    "df.rename(columns ={\"列A\": \"a\", \"列B\": \"b\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "print(\"\\n #列名変換前\")\n",
    "print(df[:3])\n",
    "\n",
    "df=df.rename(columns={\"SepalLength\":\"a\", \"SepalWidth\":\"b\" })\n",
    "print(\"\\n #列名変換後\")\n",
    "print(df[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 小ワザ4) 重複データの削除\n",
    "### 全ての列が重複したものを排除する\n",
    "df.drop_duplicates()\n",
    "\n",
    "\n",
    "### 特定のカラムに絞って利用するとdistinctになる。\n",
    "df.drop_duplicates([\"列A\", \"列B\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris_nan_error.csv\")\n",
    "\n",
    "#任意にカラム追加\n",
    "df['Group']=\"A\"  #defaultで全行に\"A\"\n",
    "df['Group'][5:9]=\"B\" # index5-9に\"B\"\n",
    "df['Group'][10:14]=\"C\" # index10-14に\"C\"\n",
    "\n",
    "# NaNを0に置換\n",
    "print(\"#重複除外前------- \")\n",
    "df=df.replace(np.nan, 0)\n",
    "print(\"\\n  レコード数:　　　\"+ str(df.index))\n",
    "print(df[:10])\n",
    "\n",
    "print(\"#完全重複を削除------- \")\n",
    "df_1= df.drop_duplicates()\n",
    "print(\"\\n  レコード数:　　　\"+ str(df_1.index))\n",
    "print(df_1[:10])\n",
    "\n",
    "print(\"#NameとGroupのdistinct------- \")\n",
    "df_2= df[[\"Name\", \"Group\"]].drop_duplicates([\"Name\", \"Group\"])\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 小ワザ5) dataframeのインデックスに任意の名前をつける\n",
    "\n",
    "df.index.name= ‘id’\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "print(\"\\n #元のデータ\")\n",
    "print(df[:3])\n",
    "\n",
    "print(\"\\n #indexに名前をつける\")\n",
    "df.index.name= \"id\"\n",
    "print(df[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 小ワザ6) dataFrameのカラムを、indexとして使用する。\n",
    "\n",
    "df.index = df.pop(\"列名\")    \n",
    "※前述の列追加で任意に作成した列などに有効"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ちょっと無理矢理感のあるデータになってしまったのですが、、\n",
    "DBのデータなどでユニークIDとNo列があって、「結合キーにはNoを使いたいんだ!!」という場合を想定してください。\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "#任意にカラム追加\n",
    "df['Group']=\"A\"  #defaultで全行に\"A\"\n",
    "df['Group'][5:9]=\"B\" # index5-9に\"B\"\n",
    "df['Group'][10:14]=\"C\" # index10-14に\"C\"\n",
    "\n",
    "print(\"\\n #元のデータ+Group\")\n",
    "print(df[:3])\n",
    "\n",
    "print(\"\\n #仮のカラム作成\")\n",
    "df[\"new_column\"]=df.index.astype(str)+\"_\"+df[\"Group\"]\n",
    "print(df[:3])\n",
    "\n",
    "df.index = df.pop(\"new_column\")\n",
    "print(df[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "# (再び)第2章 SQL文法と比較\n",
    "## 8) JOIN的なもの\n",
    "\n",
    "\n",
    "## 8-1) join\n",
    "- インデックスでの結合のみ可能。\n",
    "\n",
    "## 8-2) merge\n",
    "- インデックス以外に、データをキーにした結合が可能。(これだけでもOK)\n",
    "\n",
    "## 8-3) concat\n",
    "- インデックスでの結合のみ可能。\n",
    "-　縦にも横にも結合可能。unionするならこれを使う。\n",
    "\n",
    "\n",
    "### 以下、Mergeに絞って説明します"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## merge の使い方\n",
    "### A. インデックスをキーにする場合\n",
    "pd.merge(df1, df2 , left_index=True ,right_index=True )\n",
    "- onではなく、left_index・right_indexを使用する。\n",
    "- idでgroup_byした2つのdataframeを結合する時などに使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "print(\"\\n #index + カラム2つ のdataframe\")\n",
    "df_1=df[[\"SepalLength\", \"SepalWidth\",\"Name\"]]\n",
    "print(df_1[:5])\n",
    "\n",
    "print(\"\\n #index + 別のカラム2つ のdataframe\")\n",
    "df_2=df[[\"PetalLength\", \"PetalWidth\",\"Name\"]]\n",
    "print(df_2[:5])\n",
    "\n",
    "print(\"\\n #index でマージした結果\")\n",
    "df_3= pd.merge(df_1, df_2 , left_index=True ,right_index=True )\n",
    "print(df_3[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### B. カラムをキーにする場合\n",
    "pd.merge(df1, df2 , on='key' , how='inner')\n",
    "- ここでの'key'は2つのdataframeに共通するデータの列名を示している。\n",
    "- howには 'inner' , 'outer' , 'left' , 'right' を指定。\n",
    "- 指定がない場合は'inner'になる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\\n #カラム'No' を持つDataframe\")\n",
    "df_1= pd.read_csv(\"./iris.csv\")\n",
    "df_1= df_1[[\"SepalLength\", \"SepalWidth\",\"Name\"]]#列を絞る\n",
    "df_1[\"No\"]=df_1.index.astype(str)\n",
    "print(df_1[:3])\n",
    "\n",
    "print(\"\\n #カラム'ID' を持つDataframe\")\n",
    "df_2= pd.read_csv(\"./iris.csv\")\n",
    "df_2= df_2[[\"PetalLength\", \"PetalWidth\",\"Name\"]]#列を絞る\n",
    "df_2[\"No\"]=df_2.index.astype(str)\n",
    "print(df_2[:3])\n",
    "\n",
    "\n",
    "print(\"\\n #カラム'No'と'ID' でマージした結果\")\n",
    "df_3= pd.merge(df_1, df_2, how='inner')\n",
    "print(df_3[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 応用)キーの列名が、2つのdataframeで異なる場合\n",
    "pd.merge(df1, df2, left_on=’id’, right_on=’no’)\n",
    "- 2つのキーの型が異なる場合は、merge前に型の変換が必要\n",
    "- 例:  df[no].astype(‘str’) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\\n #カラム'No' を持つDataframe\")\n",
    "df_1= pd.read_csv(\"./iris.csv\")\n",
    "df_1[\"No\"]=df_1.index.astype(str)\n",
    "print(df_1[:3])\n",
    "\n",
    "print(\"\\n #カラム'ID' を持つDataframe\")\n",
    "df_2= pd.read_csv(\"./iris.csv\")\n",
    "df_2[\"ID\"]=df_2.index.astype(str)\n",
    "print(df_2[:3])\n",
    "\n",
    "print(\"\\n #カラム'No'と'ID' でマージした結果\")\n",
    "df_3= pd.merge(df_1, df_2, left_on='No', right_on='ID')\n",
    "print(df_3[:3])\n",
    "\n",
    "#同じ名前のカラムには\"_x\",\"_y\"がつきます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
